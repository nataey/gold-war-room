import streamlit as st
import requests
import json
import pandas as pd
import os
from newsapi import NewsApiClient
from datetime import datetime, timedelta
import re

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(page_title="Gold AI Specialist v2.5", page_icon="üí∞", layout="wide")

st.title("üí∞ Gold Market Intelligence Agent (Gemini 2.5)")
st.caption("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢ Trump & Greenland ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ Mega Project")

# ==============================================================================
# üî¥ ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Keys (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Streamlit Secrets ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà‡πÄ‡∏≠‡∏á)
# ==============================================================================
GEMINI_API_KEY = "AIzaSyBuKjq9VmJQPA5-c0FAaVl84gcniI0ugpM"
NEWS_API_KEY = "0a47175d76d1481596c418e474739272"

# Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤ War Room
OUTPUT_FILE = "data/news_intelligence.csv"
if not os.path.exists("data"): os.makedirs("data")

# ==============================================================================
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
# ==============================================================================

def get_detailed_analysis(news_list):
    # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î Gemini 2.5 Flash
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={GEMINI_API_KEY}"
    headers = {'Content-Type': 'application/json'}
    
    news_input = ""
    for i, n in enumerate(news_list):
        news_input += f"‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà {i+1} [‡πÄ‡∏ß‡∏•‡∏≤: {n['publishedAt']}]: {n['title']} - {n['description']}\n\n"

    prompt = f"""
    ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏∞‡∏ô‡∏±‡∏Å‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢ Trump (Tariff/Greenland)
    ‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
    {news_input}
    
    ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:
    {{
        "individual_news": [
            {{
                "title": "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ç‡πà‡∏≤‡∏ß‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢",
                "summary": "‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏±‡πâ‡∏ô‡πÜ",
                "weight": 0-100
            }}
        ],
        "overall_sentiment_score": 0-100,
        "overall_summary": "‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏†‡∏≤‡∏ß‡∏∞‡∏ï‡∏•‡∏≤‡∏î",
        "action_plan": "‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô"
    }}
    """
    
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
        ]
    }
    
    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            res_data = response.json()
            return res_data['candidates'][0]['content']['parts'][0]['text']
        return None
    except Exception as e:
        st.error(f"AI Error: {e}")
        return None

def clean_json_text(text):
    if not text: return None
    text = re.sub(r'```json\s*', '', text)
    text = re.sub(r'```', '', text)
    return text.strip()

# ==============================================================================
# ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• Dashboard
# ==============================================================================

if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å (Gemini 2.5 Engine)", type="primary"):
    with st.spinner('üì° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î...'):
        newsapi = NewsApiClient(api_key=NEWS_API_KEY)
        
        keywords = [
            "Gold Price impact Trump",
            "Trump Greenland", 
            "Trump 10 percent tariff", 
            "Trump trade war",
            "Federal Reserve interest rate"
        ]
        
        query_text = " OR ".join([f'"{k}"' for k in keywords])
        
        all_articles = newsapi.get_everything(
            q=query_text,
            from_param=(datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d'),
            language='en',
            sort_by='publishedAt',
            page_size=10
        )
        articles = all_articles.get('articles', [])

        if articles:
            raw_res = get_detailed_analysis(articles)
            
            if raw_res:
                try:
                    analysis = json.loads(clean_json_text(raw_res))
                    
                    # --- ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö ---
                    st.divider()
                    col_a, col_b = st.columns([1, 2])
                    with col_a:
                        st.metric("Overall Score", f"{analysis.get('overall_sentiment_score')}/100")
                    with col_b:
                        st.info(f"**‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°:** {analysis.get('overall_summary')}")
                        st.success(f"**‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** {analysis.get('action_plan')}")

                    # --- üíæ ‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Mega Project ---
                    rows = []
                    for news in analysis.get('individual_news', []):
                        rows.append({
                            "Date": datetime.now().strftime("%Y-%m-%d %H:%M"),
                            "Title": news.get('title'),
                            "Summary": news.get('summary'),
                            "Weight": news.get('weight'),
                            "Overall_Score": analysis.get('overall_sentiment_score'),
                            "Action": analysis.get('action_plan')
                        })
                    
                    df = pd.DataFrame(rows)
                    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')
                    st.toast("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤ War Room ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!", icon="üíæ")

                    st.subheader("üì∞ ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏≤‡∏¢‡∏Ç‡πà‡∏≤‡∏ß")
                    for news in analysis.get('individual_news', []):
                        with st.container(border=True):
                            c1, c2 = st.columns([4, 1])
                            with c1:
                                st.write(f"